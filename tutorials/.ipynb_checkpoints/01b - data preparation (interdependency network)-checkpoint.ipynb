{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7dab01",
   "metadata": {},
   "source": [
    "# <center>Data preparation â€“ interdependency networks</center>\n",
    "\n",
    "Prepared by Omar A. Guerrero (oguerrero@turing.ac.uk, <a href=\"https://twitter.com/guerrero_oa\">@guerrero_oa</a>)\n",
    "\n",
    "In the literature related to the Sustainable Development Goals (SDGs), much attention has been given to interdependency networks between SDGs, targets, or development indicators. One of the features of PPI is its ability to take into account such networks as an exogenous variable meant to preserve certain structure in the co-movement of the indicators. This network is considered exogenous because it is a stylised fact of the system under study, not a causal account of the relationship between the indicators. While many studies attempt at making causal claims from such objects, we have shown (in the book and in multiple publications) that such statements cannot be causal (see https://doi.org/10.1016/j.im.2020.103342 for an example and for a list of potential methods). Thus, the aim in this tutorial is to show how to prepare the data for the network input of PPI.\n",
    "\n",
    "In the book, as in most of PPI's studies, I have employed a method called `sparsebn` (http://doi.org/10.18637/jss.v091.i11). However, for the sake of simplicity in these tutorials, I take a simple correlation approach to construct the network. First, I will load the pre-processed indicator data obtained from the previous tutorial. Then, I will estimate pairwise correlations between the changes of two time series. Importantly, one of change vectors will be lagged. This allows constructing a directed asymmetric network. Next, I will filter out edges using an arbitrary threshold criterion. Finally, I will structure the data and export it.\n",
    "\n",
    "Remember, this procedure is only for the purpose of illustration, and should not be considered a standard for producing interdependency networks. The choice of the network-estimation method depends on the problem and data at hand, and there is no gold standard for the case of SDG indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4a377d",
   "metadata": {},
   "source": [
    "## Import the necessary Python libraries to manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f033da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d138d7",
   "metadata": {},
   "source": [
    "## Import the raw development indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3097fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/oguerrer/ppi/main/tutorials/clean_data/data_indicators.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604a8e53",
   "metadata": {},
   "source": [
    "## Construct a matrix with pairwise Pearson correlations\n",
    "\n",
    "The directionality of the edges is from row to column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc363d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "M = np.zeros((N, N))\n",
    "years = [column_name for column_name in data.columns if str(column_name).isnumeric()]\n",
    "\n",
    "for i, rowi in data.iterrows():\n",
    "    for j, rowj in data.iterrows():\n",
    "        if i!=j:\n",
    "            serie1 = rowi[years].values.astype(float)[1::]\n",
    "            serie2 = rowj[years].values.astype(float)[0:-1]\n",
    "            change_serie1 = serie1[1::] - serie1[0:-1]\n",
    "            change_serie2 = serie2[1::] - serie2[0:-1]\n",
    "            if not np.all(change_serie1 == change_serie1[0]) and not np.all(change_serie2 == change_serie2[0]):\n",
    "                M[i,j] = np.corrcoef(change_serie1, change_serie2)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58dbad",
   "metadata": {},
   "source": [
    "## Filter edges that have a weight of magnitude lower than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c522a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[np.abs(M) < 0.5] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a461f0",
   "metadata": {},
   "source": [
    "## Save the network as a list of edges using the indicators' ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071a5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = data.seriesCode.values\n",
    "edge_list = []\n",
    "for i, j in zip(np.where(M!=0)[0], np.where(M!=0)[1]):\n",
    "    edge_list.append( [ids[i], ids[j], M[i,j]] )\n",
    "df = pd.DataFrame(edge_list, columns=['origin', 'destination', 'weight'])\n",
    "df.to_csv('clean_data/data_network.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
